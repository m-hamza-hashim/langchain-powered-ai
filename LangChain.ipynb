{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8jol-iabHFO"
   },
   "source": [
    "# DISCLAIMER: Use litellm as chatmodel within langchain to enable easy switching between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqSUIUZsJb5i"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "####langchain gemin hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9064,
     "status": "ok",
     "timestamp": 1737019675758,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "nDgy_LKLFH7r",
    "outputId": "49972821-f7d2-4ac8-bd2a-3e523dec4d04"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain-google-genai\n",
    "\n",
    "from google.colab import userdata\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "print(llm.invoke(\"Sing a ballad of LangChain.\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3287,
     "status": "ok",
     "timestamp": 1736704992172,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "Gil4DRbrjYRz",
    "outputId": "edbb134b-b2c8-444c-ea72-174779313795"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\")\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What's in this image?\",\n",
    "        },  # You can optionally provide text parts\n",
    "        {\"type\": \"image_url\", \"image_url\": \"https://picsum.photos/seed/picsum/200/300\"},\n",
    "    ]\n",
    ")\n",
    "print(llm.invoke([message]).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN3kw2fbJIwQ"
   },
   "source": [
    "#RAG\n",
    "\n",
    "## Making a rag system (in langchain)\n",
    "### 1) create the vectorstore\n",
    "### 2) make llm\n",
    "### 3) query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-A82ztgHbf4e"
   },
   "source": [
    "## making vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9527,
     "status": "ok",
     "timestamp": 1737019685276,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "kPRpqpKQX6SE",
    "outputId": "b9ec7758-29b0-4077-8fbc-c305ce30401c"
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain-pinecone pinecone-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmiqK7pKX9nb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from google.colab import userdata\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = userdata.get('PINECONE_API_KEY')\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sf3cF27YQnO"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"hello\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wy2JftFeZhXN"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AADmWPVyZk4z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6WY8g0YZ9ml"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 745,
     "status": "ok",
     "timestamp": 1737019692962,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "GTscVVVibISI",
    "outputId": "31fd6a1d-810b-4d1d-f9af-10b0db8ebeb0"
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GULQEJkbcKf"
   },
   "source": [
    "## making llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_jj17kYkbBCx"
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain-google-genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mehUnLGsbYsC"
   },
   "source": [
    "## querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4sn9ZgMbl2M"
   },
   "outputs": [],
   "source": [
    "query: str = \"tell about shark\"\n",
    "\n",
    "results = vector_store.similarity_search(\n",
    "    query,\n",
    "    k=1,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6R9xBzufp_q"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"Answer the query using the references mentioned only\",\n",
    "    ),\n",
    "    (\"human\", f\"Query: {query}. References: {results}\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1737020104156,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "6yyPJ5Xzf9Hp",
    "outputId": "8c0022a2-29a8-497a-a61f-9f8c3c57dc03"
   },
   "outputs": [],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzlIEnhjXFoa"
   },
   "source": [
    "# ADV RAG\n",
    "## 1) make the vector store\n",
    "## 2) make the retriever\n",
    "## 3) make the llm\n",
    "## 4) make the prompt\n",
    "## 5) make the chain\n",
    "## 6) query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckbHxLPdZZjr"
   },
   "source": [
    "## making vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mF-Uh2w4XSrA"
   },
   "outputs": [],
   "source": [
    "!pip install -qU \"langchain-chroma>=0.1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4228,
     "status": "ok",
     "timestamp": 1737018526832,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "KZRKDszjXypG",
    "outputId": "aaa164e1-f445-4dac-9e8e-e893eebf76da"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBFyb21SX3tj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Yw56sWqX_7D"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPgNhc0SYJHn"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"first\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1824,
     "status": "ok",
     "timestamp": 1737018755720,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "pKivitRDYoAF",
    "outputId": "503fde1d-01e9-4b13-c6d6-77592f9e3511"
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=3,\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=4,\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=5,\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=6,\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=7,\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=8,\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=9,\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YLK5L5zZdnt"
   },
   "source": [
    "## making retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRF9mGBwZUiD"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "retriever = RunnableLambda(vector_store.similarity_search).bind(k=1)  # select top result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5VqwswfZtHs"
   },
   "source": [
    "## making llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkCOIHocZuY3"
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yGxclD4Z11K"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8hNz4VLdHon"
   },
   "source": [
    "## making prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNVJrJ7ZZ6L4"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "message = \"\"\"\n",
    "Answer this question using the provided context only.\n",
    "\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQfvDu5iaXtg"
   },
   "source": [
    "## chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umuYwJYeaR98"
   },
   "outputs": [],
   "source": [
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC4_Ruflam1X"
   },
   "source": [
    "## querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5357,
     "status": "ok",
     "timestamp": 1737019599717,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "3fhT9FzpafLq",
    "outputId": "c8c87f66-adfa-46c7-de96-106b90e0ca36"
   },
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(\"tell about shark\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDwL35issVeX"
   },
   "source": [
    "# ADV RAG USING DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40094,
     "status": "ok",
     "timestamp": 1737191581350,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "s0XaWR9R7tdv",
    "outputId": "8121dd6d-2df6-4ba3-894f-bdcebdf4413a"
   },
   "outputs": [],
   "source": [
    "!pip install -qU \"langchain-chroma>=0.1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4486,
     "status": "ok",
     "timestamp": 1737191585811,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "kBocedO47td7",
    "outputId": "94bbdf1b-d9a6-4c53-81f8-f989f264904c"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i01HpsTt7td8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hu3oNgil7td9"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJWvvXo57td-"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"first\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8866,
     "status": "ok",
     "timestamp": 1737192918179,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "E_j1p_xcxAtL",
    "outputId": "e7e069e6-4776-40bf-e009-6c38c2fd2ca9"
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain_community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4l5l_ox6xDpB"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "    \"resume.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1737193079302,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "qTxABoJoxQud",
    "outputId": "6805d9cb-4e6a-471f-d909-3ea7bdc959c3"
   },
   "outputs": [],
   "source": [
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 796,
     "status": "ok",
     "timestamp": 1737193198493,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "JHSEDBl77teE",
    "outputId": "cdfb4913-3e18-42b7-9b53-146f4a680d07"
   },
   "outputs": [],
   "source": [
    "\n",
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-U9kqsc7teH"
   },
   "source": [
    "## making retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m25GjIfb7teI"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "retriever = RunnableLambda(vector_store.similarity_search).bind(k=1)  # select top result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pt3XlxYu7teJ"
   },
   "source": [
    "## making llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OctqPE_K7teK"
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7nDn_7j7teL"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6HKWTne7teM"
   },
   "source": [
    "## making prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXYCLzV57teN"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "message = \"\"\"\n",
    "Answer this question using the provided context only.\n",
    "\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pqq2m92_7teP"
   },
   "source": [
    "## chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0BYIw_E7teQ"
   },
   "outputs": [],
   "source": [
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aenBi-lD7teR"
   },
   "source": [
    "## querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1507,
     "status": "ok",
     "timestamp": 1737193231409,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "lyeAZMWd7teS",
    "outputId": "f3aa930b-83d8-4ce0-84ce-3534fee597bb"
   },
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(\"which university does hamza  go to?\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD0bYzFfj-Rs"
   },
   "source": [
    "# face detection using a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135244,
     "status": "ok",
     "timestamp": 1737022014998,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "QeQQ9ohuUMqS",
    "outputId": "da01638a-a838-4a17-f454-24d9081b01b1"
   },
   "outputs": [],
   "source": [
    "!pip install -Uq facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeWUwMq_ONLJ"
   },
   "outputs": [],
   "source": [
    "!pip install -Uq pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLF-hrWBKmod"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "919dc78a9f384cdcacfebb4cf48922a7",
      "6e5b2875a6ea4a9db096403f3e1af121",
      "ff473d97dbaf437ebf36105c53ca49e5",
      "2534a68f0a934d28b2a465af879c29f1",
      "89c565618bd140aabd7f2862d17c2d53",
      "39aeb866e1ca4fc181d50460da32bdc2",
      "488d34e43dea4d40b2cdb4c5ee1acc31",
      "1419e042687048af80a71bf3a07fb9c2",
      "467925991120492d861be7f238f88e37",
      "af52f8d197db4ed3b8d7b4bde87ec145",
      "7685a6b25e7a40cfb320db213fb33a30"
     ]
    },
    "executionInfo": {
     "elapsed": 2159,
     "status": "ok",
     "timestamp": 1737022043903,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "22HAeuDqTolW",
    "outputId": "782085cf-83cd-40ad-abb4-991f993af9c8"
   },
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtY6raX6Vrsp"
   },
   "outputs": [],
   "source": [
    "# Preprocessing function to transform the image into a tensor\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return preprocess(image).unsqueeze(0)\n",
    "\n",
    "# Function to create image embeddings\n",
    "def create_image_embedding(image_path):\n",
    "    try:\n",
    "        input_tensor = preprocess_image(image_path)\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(input_tensor)# ebedding important line\n",
    "        return embeddings.squeeze().numpy()\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0AcRHbRVslq"
   },
   "outputs": [],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhtkU-0lV1-O"
   },
   "outputs": [],
   "source": [
    "# prompt: create python function where we provide image url and imag_name then it save in images folder\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def save_image_from_url(image_url, image_name):\n",
    "  \"\"\"\n",
    "  Downloads an image from a URL and saves it to the 'images' folder.\n",
    "\n",
    "  Args:\n",
    "    image_url: The URL of the image to download.\n",
    "    image_name: The name of the file to save the image as.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    if not os.path.exists(\"images\"):\n",
    "      os.makedirs(\"images\")\n",
    "\n",
    "    image_path = os.path.join(\"images\", image_name)\n",
    "\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    response.raise_for_status()  # Raise an exception for bad status codes\n",
    "\n",
    "    with open(image_path, 'wb') as file:\n",
    "      for chunk in response.iter_content(chunk_size=8192):\n",
    "        file.write(chunk)\n",
    "\n",
    "    print(f\"Image saved to: {image_path}\")\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading image: {e}\")\n",
    "  except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1327,
     "status": "ok",
     "timestamp": 1737022807218,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "01gSmY8gX8ep",
    "outputId": "60038b38-a610-4d87-dd67-16ddcd9fd3b4"
   },
   "outputs": [],
   "source": [
    "save_image_from_url(\"https://avatars.githubusercontent.com/u/10209765?v=4\", \"q1.jpg\")\n",
    "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4D22AQFmuEiR8ttUmw/feedshare-shrink_800/feedshare-shrink_800/0/1711203894556?e=2147483647&v=beta&t=GEZGp_cdogNJCJIGidoEw_DjW2FXZcG4nUUlaNF1Zlc\",\"z1.jpg\")\n",
    "save_image_from_url(\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQBBiqefc7Le97Rn0udVVBkur7RlU53FcQh1A&s\",'z2.jpg')\n",
    "save_image_from_url(\"https://i.ytimg.com/vi/7QD3GKvSyMk/hqdefault.jpg?sqp=-oaymwEmCOADEOgC8quKqQMa8AEB-AHOBYAC0AWKAgwIABABGGUgXChPMA8=&rs=AOn4CLB2EaZsLrClGHqUMUhApQ_sxAcF7Q\",\"q2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1737022816645,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "ZtpE6lWvW3gD",
    "outputId": "ad89c0b9-9a10-4b7e-ba90-814908d8763a"
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = \"./images/q2.jpg\"\n",
    "q2 = create_image_embedding(image_path)\n",
    "\n",
    "# 'embedding' now contains a dense vector representation of the image\n",
    "print(\"Image Embedding Shape:\", q2.shape)\n",
    "print(\"Image Embedding:\", q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1737022836580,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "qGsGyHm7Z7GG",
    "outputId": "fa2244b0-2c15-4d6d-afa2-2b60d2e5593d"
   },
   "outputs": [],
   "source": [
    "q1 = create_image_embedding(\"./images/q1.jpg\")\n",
    "q2 = create_image_embedding(\"./images/q2.jpg\")\n",
    "s1 = create_image_embedding(\"./images/s1.jpg\")\n",
    "s2 = create_image_embedding(\"./images/s2.jpg\")\n",
    "z1 = create_image_embedding(\"./images/z1.jpg\")\n",
    "z2 = create_image_embedding(\"./images/z2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11597,
     "status": "ok",
     "timestamp": 1737022857935,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "EaGMoOeMatEn",
    "outputId": "a794c073-4380-43a4-b2d1-a5822f83a6c0"
   },
   "outputs": [],
   "source": [
    "!pip install -U milvus-lite\n",
    "\n",
    "!pip install -U pymilvus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VCan5cjbCBW"
   },
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "client = MilvusClient(\"./milvus_demo.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhSATnNMaZmf"
   },
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "import numpy as np\n",
    "\n",
    "client = MilvusClient(\"./milvus_demo.db\")\n",
    "client.create_collection(\n",
    "    collection_name=\"images\",\n",
    "    dimension=512  # The vectors we will use in this demo has 384 dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bB-wjZmIarV3"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"id\": 1, \"person_name\": \"Qasim\", \"vector\": q1},\n",
    "    {\"id\": 2, \"person_name\": \"Qasim\", \"vector\": q2},\n",
    "    {\"id\": 3, \"person_name\": \"Zia Khan\", \"vector\": z1},\n",
    "    {\"id\": 4, \"person_name\": \"Zia Khan\", \"vector\": z2}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPFMGNspcEnF"
   },
   "outputs": [],
   "source": [
    "res = client.insert(\n",
    "    collection_name=\"images\",\n",
    "    data=data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1737022861098,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "0E3TbHNIaZsF",
    "outputId": "235b67d2-42ac-4c21-d12d-fbd01f17608d"
   },
   "outputs": [],
   "source": [
    "res = client.search(\n",
    "    collection_name=\"images\",\n",
    "    data=[q1],\n",
    "    limit=1,\n",
    "    output_fields=[\"id\", \"person_name\"],\n",
    ")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1737022864857,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "CWjC3uQyaZ0h",
    "outputId": "3e334dcc-1958-47b3-da85-497f08cfa250"
   },
   "outputs": [],
   "source": [
    "# t1 is qasim's same pic as q1\n",
    "save_image_from_url(\"https://avatars.githubusercontent.com/u/10209765?v=4\", \"t1.jpg\")\n",
    "t1 = create_image_embedding('./images/t1.jpg')\n",
    "t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1737022917833,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "Pr7oM5Otf2My",
    "outputId": "a1a22aa0-9687-43e1-88f3-6d414c792b37"
   },
   "outputs": [],
   "source": [
    "res = client.search(\n",
    "    collection_name=\"images\",\n",
    "    data=[t1],\n",
    "    limit=1,\n",
    "    output_fields=[\"id\", \"person_name\"],\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1737022926328,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "Khvv6CpNfNaj",
    "outputId": "04704be6-1028-4c85-dc4e-40a35a9dd958"
   },
   "outputs": [],
   "source": [
    "# t2 is bill gates pic\n",
    "save_image_from_url(\"https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4000x2667+0+0/resize/1100/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F82%2Ffb%2F62f7bcdd47329b5419411e9a7471%2Fbill-gates-portrait-at-npr.jpg\", \"t2.jpg\")\n",
    "t2 = create_image_embedding('./images/t2.jpg')\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1737022933260,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "MiMKGVPGgBku",
    "outputId": "59a79436-7001-482d-9e6b-2643bbaa11e8"
   },
   "outputs": [],
   "source": [
    "res = client.search(\n",
    "    collection_name=\"images\",\n",
    "    data=[t2],\n",
    "    limit=1,\n",
    "    output_fields=[\"id\", \"person_name\"],\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1737022937253,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "T1ERg8MEiO2S",
    "outputId": "1e532434-ab35-47b6-df8b-d21630bb590c"
   },
   "outputs": [],
   "source": [
    "# t3 is zia khan's new img\n",
    "save_image_from_url(\"https://static.wixstatic.com/media/db6d86_c3ff0ba2fb6d45ad8d168621a2525cd0~mv2.png/v1/crop/x_0,y_18,w_2400,h_2340/fill/w_319,h_311,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/Mr_%20Zia%20Khan.png\", \"t3.jpg\")\n",
    "t3 = create_image_embedding('./images/t3.jpg')\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1737022943741,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "XLF72_K0gJTg",
    "outputId": "d3c2306e-2bea-441f-eaeb-96662253ceb1"
   },
   "outputs": [],
   "source": [
    "res = client.search(\n",
    "    collection_name=\"images\",\n",
    "    data=[t3],\n",
    "    limit=1,\n",
    "    output_fields=[\"id\", \"person_name\"],\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyRU7a5pKiqb"
   },
   "source": [
    "#VOICE DETECTION USING VECTOR DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17285300"
   },
   "outputs": [],
   "source": [
    "!pip install -Uq tensorflow_hub  pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4875,
     "status": "ok",
     "timestamp": 1737140040295,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "0a415bd2",
    "outputId": "e7af035f-abee-45e5-cb5b-1f2887b8f35d"
   },
   "outputs": [],
   "source": [
    "!pip install -Uq tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17295,
     "status": "ok",
     "timestamp": 1737139779960,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "ZcI7XuU-P5ht",
    "outputId": "b2b87fbb-cd29-401c-de0b-0308a186b4e5"
   },
   "outputs": [],
   "source": [
    "# Step 1: Download the audio files\n",
    "!mkdir audios\n",
    "!wget -O audios/h1.wav \"https://www.wavsource.com/snds_2020-10-01_3728627494378403/people/famous/hawking01.wav\"\n",
    "!wget -O audios/h2.wav \"https://www.wavsource.com/snds_2020-10-01_3728627494378403/people/famous/hawking02.wav\"\n",
    "!wget -O audios/l1.wav \"https://www.wavsource.com/snds_2020-10-01_3728627494378403/people/famous/king_injustice.wav\"\n",
    "!wget -O audios/l2.wav \"https://www.wavsource.com/snds_2020-10-01_3728627494378403/people/famous/king_nonviolence.wav\"\n",
    "!wget -O audios/m1.wav \"https://www.wavsource.com/snds_2020-10-01_3728627494378403/people/famous/manson_believe_me.wav\"\n",
    "!wget -O audios/m2.wav \"https://www.wavsource.com/snds_2020-10-01_3728627494378403/people/famous/manson_devil.wav\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4242,
     "status": "ok",
     "timestamp": 1737139811262,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "JuRnek7Rlky6",
    "outputId": "8c8ffc2e-0863-4293-921f-9ea0f02d16e5"
   },
   "outputs": [],
   "source": [
    "# # Step 2: Install ffmpeg if not already installed\n",
    "!apt-get install ffmpeg\n",
    "\n",
    "# # Step 3: Convert audio files to 16-bit WAV\n",
    "!ffmpeg -i audios/h1.wav -acodec pcm_s16le -ar 44100 audios/h1_16.wav\n",
    "!ffmpeg -i audios/h2.wav -acodec pcm_s16le -ar 44100 audios/h2_16.wav\n",
    "!ffmpeg -i audios/m1.wav -acodec pcm_s16le -ar 44100 audios/m1_16.wav\n",
    "!ffmpeg -i audios/m2.wav -acodec pcm_s16le -ar 44100 audios/m2_16.wav\n",
    "!ffmpeg -i audios/l1.wav -acodec pcm_s16le -ar 44100 audios/l1_16.wav\n",
    "!ffmpeg -i audios/l2.wav -acodec pcm_s16le -ar 44100 audios/l2_16.wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1737140005291,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "UCGrnepImjxd",
    "outputId": "c20ca35d-82c5-4cfc-b8bf-3f27218b5728"
   },
   "outputs": [],
   "source": [
    "\n",
    "!rm audios/h1.wav audios/h2.wav audios/m1.wav audios/m2.wav audios/l1.wav audios/l2.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6821,
     "status": "ok",
     "timestamp": 1737140070394,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "099a8f73",
    "outputId": "9ba0c302-f2a8-47ea-d27a-09dfe29ed3df"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load the YAMNET model\n",
    "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "\n",
    "# Load an audio file\n",
    "audio, sample_rate = tf.audio.decode_wav(tf.io.read_file('audios/h1_16.wav'))\n",
    "audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "# Generate embeddings\n",
    "scores, embeddings, log_mel_spectrogram = model(audio)\n",
    "\n",
    "print(f\"Audio embedding shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1737140076096,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "e3df3238",
    "outputId": "c2c89f3e-0378-45c7-ea3e-e5645e9ef245"
   },
   "outputs": [],
   "source": [
    "# Load an audio file\n",
    "audio, sample_rate = tf.audio.decode_wav(tf.io.read_file('audios/m1_16.wav'))\n",
    "audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "scores, embeddings, log_mel_spectrogram = model(audio)\n",
    "\n",
    "print(f\"Audio embedding shape: {embeddings.shape}\")#27,18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1737140078375,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "f0781c9f",
    "outputId": "f3e35b22-fc19-4245-af86-386843cfa75f"
   },
   "outputs": [],
   "source": [
    "log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "235d4679"
   },
   "source": [
    "#  we found shape dimension error\n",
    "* you can solve with slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2071,
     "status": "ok",
     "timestamp": 1737140086279,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "5383fe62",
    "outputId": "6ce78dd8-19fd-4654-d2d5-fc16a08179f3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "voices = []\n",
    "labels = []\n",
    "for i in os.listdir(\"./audios/\"):\n",
    "    if '.wav' in i:\n",
    "        name = i.split(\".\")[0]\n",
    "\n",
    "\n",
    "        audio, sample_rate = tf.audio.decode_wav(tf.io.read_file(f'./audios/{i}'))\n",
    "        audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "        scores, embeddings, log_mel_spectrogram = model(audio)\n",
    "\n",
    "        voices.append(np.array(embeddings[:5,:]).ravel())\n",
    "        labels.append(name)\n",
    "\n",
    "        print(f\"Audio embedding shape: {embeddings.shape} new shape {embeddings[:5,:].shape} type {type(np.array(embeddings[:18,:]))}\")#27,18\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1737140093869,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "da7e4a33",
    "outputId": "b9d387fc-49de-4b0c-e02c-027cb60a0e5a"
   },
   "outputs": [],
   "source": [
    "voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7477,
     "status": "ok",
     "timestamp": 1737140135907,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "XXVc-11rnn6l",
    "outputId": "450242e4-1a87-4f6a-c904-db48cef3002c"
   },
   "outputs": [],
   "source": [
    "!pip install pymilvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 824,
     "status": "error",
     "timestamp": 1737140140991,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "a4a47001",
    "outputId": "f3bcead1-5dc2-471b-f651-56c568344c2a"
   },
   "outputs": [],
   "source": [
    "#Imports a PyMilvus package:\n",
    "\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    ")\n",
    "\n",
    "#Connect to the Milvus\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "# Define the collection name\n",
    "collection_name = \"audio\"\n",
    "\n",
    "# Delete old collection if it exists\n",
    "if utility.has_collection(collection_name):\n",
    "    Collection(collection_name).drop()\n",
    "\n",
    "\n",
    "#Creates a collection:\n",
    "fields = [\n",
    "    FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
    "    FieldSchema(name=\"words\", dtype=DataType.VARCHAR, max_length=50),\n",
    "    FieldSchema(name=\"person_name\", dtype=DataType.VARCHAR, max_length=50),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=5120)\n",
    "]\n",
    "schema = CollectionSchema(fields, \"Simple Demo for audio similar search\")\n",
    "audio = Collection(\"audio\", schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c6ff703",
    "outputId": "67498be3-37a0-4524-da44-149e90eacff6"
   },
   "outputs": [],
   "source": [
    "# Builds indexes on the entities:\n",
    "\n",
    "index = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "\n",
    "audio.create_index(\"embeddings\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38a067e1",
    "outputId": "31012c7a-8e66-410d-f57e-e3d8f9b165f4"
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63acee52",
    "outputId": "017865cd-df18-4dc8-e2fd-67793aa6c178"
   },
   "outputs": [],
   "source": [
    "voices[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "498bb584"
   },
   "outputs": [],
   "source": [
    "#Insert data in collection\n",
    "data = [\n",
    "    [1,2,3,4,5,6],  # field pk\n",
    "    labels,  # field words\n",
    "    [\"Auranzaib\",\"Auranzaib\",\"Hasnant\",\"Qasim\",\"Hasnant\",\"Qasim\"],\n",
    "    voices,  # field embeddings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7f1cecb9"
   },
   "outputs": [],
   "source": [
    "audio.insert(data)\n",
    "audio.flush()\n",
    "audio.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "add38b06"
   },
   "outputs": [],
   "source": [
    "search_params = {\"metric_type\": \"L2\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8629381c"
   },
   "outputs": [],
   "source": [
    "results = audio.search(\n",
    "\tdata=[voices[0]],\n",
    "\tanns_field=\"embeddings\",\n",
    "\tparam=search_params,\n",
    "\tlimit=4,\n",
    "\texpr=None,\n",
    "\t# set the names of the fields you want to retrieve from the search result.\n",
    "\toutput_fields=['words','person_name'],\n",
    "\tconsistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "760df8e0",
    "outputId": "af22d2a2-caee-471a-bcc4-fb9f78baca08"
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(results[0])):\n",
    "    name = results[0][i].entity.get('words')\n",
    "    pname = results[0][i].entity.get('person_name')\n",
    "    print(pname)\n",
    "#     try:\n",
    "#         display(Image.open('./images/'+name+'.jpg'))\n",
    "#     except:\n",
    "#         display(Image.open('./images/'+name+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7b1c4b0b",
    "outputId": "f25dd8ab-f236-418b-89b7-fa4d94c0110c"
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8HIAy28uJW1"
   },
   "source": [
    "# Langchain Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDsIhkozuh9a"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3803,
     "status": "ok",
     "timestamp": 1737746028900,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "kG5724ORuxAh",
    "outputId": "03ee7df1-a3ff-4788-e52c-84e7d424c9b8"
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BsHjhBIvEYP"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57mKbAFRzKIT"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1583,
     "status": "ok",
     "timestamp": 1737747212152,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "W3P3aY-RvLyS",
    "outputId": "b98d24a3-556f-4f6a-d66b-0c89e85d35bf"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1737747418577,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "7ldZkCWhwcIW",
    "outputId": "c8d7eeca-f3c8-46a4-e39f-f0ddcf7f738d"
   },
   "outputs": [],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "print(messages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1570,
     "status": "ok",
     "timestamp": 1737747379963,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "Z78NgRRrxKOZ",
    "outputId": "e34b8613-562a-4b86-e0be-a46333a8dab6"
   },
   "outputs": [],
   "source": [
    "print(llm_with_tools.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCe-JGRQ09br"
   },
   "source": [
    "# Langchain tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3224,
     "status": "ok",
     "timestamp": 1737748646539,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "xJBlQZpD4-VS",
    "outputId": "a6701f3a-2c6e-4be5-d40b-b22eefcaabb6"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade stackapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApYlSru2_sfA"
   },
   "outputs": [],
   "source": [
    "from langchain_community.utilities import StackExchangeAPIWrapper\n",
    "\n",
    "@tool\n",
    "def stackexchange(query: str) -> str:\n",
    "  \"\"\"Executes a search query on StackExchange and returns relevant answers or posts.\n",
    "  - `query`: The user's search or troubleshooting question.\n",
    "  - Returns: Top results from StackExchange.\"\"\"\n",
    "  return StackExchangeAPIWrapper().run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKAYQL8I9qbe"
   },
   "outputs": [],
   "source": [
    "tools = [stackexchange]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9534,
     "status": "ok",
     "timestamp": 1737751041479,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "g6BAEbqZAGhq",
    "outputId": "90a7a1e9-58ad-4b22-c4d5-6b8cd0453136"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"zsh: command not found: python\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2823,
     "status": "ok",
     "timestamp": 1737751244576,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "61gX9u4-AGhs",
    "outputId": "8836b231-2fee-440d-f03a-68d1b741a3d1"
   },
   "outputs": [],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"stackexchange\": stackexchange}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "print(messages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12039,
     "status": "ok",
     "timestamp": 1737751118389,
     "user": {
      "displayName": "Hamza Hashim",
      "userId": "13752771049705334670"
     },
     "user_tz": -300
    },
    "id": "s4yopM6CAGht",
    "outputId": "ea8f4313-eb13-48ee-86b8-be20cec16d6a"
   },
   "outputs": [],
   "source": [
    "print(llm_with_tools.invoke(messages).content)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPTbIYsoR8EVaeoZm8fHbpM",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
